# -*- coding: utf-8 -*-
"""code  projet Chatbot juridique avec RAG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WO0l9sE-bZwZsWAInaNKHig9XdvoFEYo
"""
#lien vers data dans colab : https://drive.google.com/drive/folders/1W8V8cXS5Gby8H7SpKSzwhe_TmaqH50qC?usp=sharing
!pip install transformers sentence-transformers faiss-cpu PyPDF2 gradio

from google.colab import drive
drive.mount('/content/drive')

"""√âtape 1 : Charger et extraire le texte des PDFs"""

from PyPDF2 import PdfReader

def extract_text(pdf_path):
    reader = PdfReader(pdf_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

# Exemple : mettre le chemin vers ton PDF
text = extract_text("/content/drive/MyDrive/projet nlp/Code du travail - LeÃÅgifrance.pdf")
print(text[:500])  # affiche le d√©but pour v√©rifier

"""√âtape 2 : D√©couper le texte en chunks"""

def chunk_text(text, chunk_size=500, overlap=50):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

chunks = chunk_text(text)
print(f"Nombre de chunks : {len(chunks)}")
print(chunks[0])  # v√©rifier le premier chunk

"""√âTAPE 3 : Embeddings + Index FAISS (le c≈ìur du RAG)"""

!pip install sentence-transformers faiss-cpu

"""3.2 Charger le mod√®le d‚Äôembeddings

On utilise Sentence-BERT (tr√®s bon pour le RAG).
"""

from sentence_transformers import SentenceTransformer

embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

"""3.3 Calculer les embeddings des chunks"""

import numpy as np

embeddings = embedding_model.encode(
    chunks,
    show_progress_bar=True,
    convert_to_numpy=True
)

print("Shape des embeddings :", embeddings.shape)

"""3.4 Cr√©er l‚Äôindex FAISS

"""

import faiss

dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

print("Nombre de vecteurs dans l'index :", index.ntotal)

"""3.5 Test du retrieval (super important)"""

def retrieve_chunks(question, k=3):
    question_embedding = embedding_model.encode([question])
    distances, indices = index.search(question_embedding, k)
    return [chunks[i] for i in indices[0]]

question = "Quels sont les droits du salari√© en cas de licenciement ?"
results = retrieve_chunks(question)

for i, res in enumerate(results):
    print(f"\n--- Passage {i+1} ---\n")
    print(res[:500])

"""√âTAPE 4 : G√©n√©ration de r√©ponse avec LLM (RAG complet)

4.1 Installer le LLM
"""

!pip install transformers accelerate

"""4.2 Charger le mod√®le LLM

On prend un mod√®le l√©ger mais efficace pour QA.
"""

from transformers import pipeline

llm = pipeline(
    "text-generation",
    model="mistralai/Mistral-7B-Instruct-v0.2",
    max_new_tokens=300,
    temperature=0.2
)

"""4.3 Construire le prompt RAG"""

def build_prompt(question, retrieved_chunks):
    context = "\n\n".join(retrieved_chunks)

    prompt = f"""
Tu es un assistant juridique sp√©cialis√© en droit du travail fran√ßais.

R√©ponds uniquement √† partir des extraits suivants.
Si la r√©ponse n'est pas pr√©sente, dis clairement : "Je ne sais pas".

Extraits :
{context}

Question :
{question}

R√©ponse (avec citation des articles ou sources si possible) :
"""
    return prompt

"""4.4 G√©n√©rer la r√©ponse finale"""

prompt = build_prompt(question, results)

response = llm(prompt)[0]["generated_text"]

print(response)

"""√âTAPE 5 : Interface Chatbot avec Gradio

5.1 Installer Gradio
"""

!pip install gradio transformers accelerate

"""5.2 Chargement du LLM"""

from transformers import pipeline

llm = pipeline(
    "text2text-generation",
    model="google/flan-t5-base",
    max_new_tokens=300
)

"""5.3 Prompt RAG"""

def build_prompt(question, retrieved_chunks):
    context = "\n\n".join(retrieved_chunks)
    return f"""
You are a legal assistant specialized ONLY in the French Labour Code (Code du travail).

Answer the question ONLY using the articles from the Code du travail provided below.
If the answer is not found in these articles, say exactly: Je ne sais pas.

Code du travail excerpts:
{context}

Question:
{question}

Answer (mention articles if possible):
"""

"""5.4 Fonction Chatbot"""

def chatbot(question):
    try:
        retrieved = retrieve_chunks(question, k=3)
        prompt = build_prompt(question, retrieved)
        result = llm(prompt)
        return result[0]["generated_text"]
    except Exception as e:
        return f"Erreur interne : {str(e)}"

"""5.5 Interface Gradio"""

import gradio as gr

interface = gr.Interface(
    fn=chatbot,
    inputs=gr.Textbox(lines=2, placeholder="Posez votre question en droit du travail..."),
    outputs=gr.Textbox(label="R√©ponse du chatbot"),
    title="ü§ñ Chatbot juridique ‚Äì Droit du travail (RAG)",
    description="Ce chatbot r√©pond √† des questions juridiques simples √† partir du Code du travail."
)

interface.launch(share=True, debug=True)